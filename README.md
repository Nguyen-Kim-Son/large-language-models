# üó£Ô∏è M√¥ h√¨nh ng√¥n ng·ªØ l·ªõn (Large Language Model - LLM)

Kh√≥a h·ªçc n√†y ƒë∆∞·ª£c chia th√†nh 02 ph·∫ßn:

1. üß© **C∆° b·∫£n v·ªÅ LLM** bao g·ªìm c√°c ki·∫øn th·ª©c v·ªÅ to√°n h·ªçc , Python, v√† m·∫°ng n∆° ron.
2. üßë‚Äçüî¨ **Nh√† nghi√™n c·ª©u LLM** t·∫≠p trung v√†o h·ªçc c√°ch l√†m th·∫ø n√†o ƒë·ªÉ x√¢y d·ª±ng ki·∫øn tr√∫c LLMs t·ªët nh·∫•t b·∫±ng c√°ch s·ª≠ d·ª•ng k·ªπ thu·∫≠t m·ªõi nh·∫•t. 

## üìù Notebooks

Danh s√°ch c√°c code m·∫´u v√† b√†i vi·∫øt li√™n quan ƒë·∫øn LLM 

### Tinh ch·ªânh (Fine-tuning)

| Notebook | M√¥ t·∫£ | B√†i vi·∫øt | Notebook |
|---------------------------------------|-------------------------------------------------------------------------|---------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------|
| Tinh ch·ªânh Llama 2 trong Google Colab | H∆∞·ªõng d·∫´n t·ª´ng b∆∞·ªõc ƒë·ªÉ tinh ch·ªânh m√¥ h√¨nh Llama 2. | [Article](https://mlabonne.github.io/blog/posts/Fine_Tune_Your_Own_Llama_2_Model_in_a_Colab_Notebook.html) | <a href="https://colab.research.google.com/drive/1PEQyJO1-f6j0S_XJ8DV50NkpzasXkrzd?usp=sharing"><img src="images/colab.svg" alt="Open In Colab"></a> |
| Tinh ch·ªânh LLMs v·ªõi Axolotl | H∆∞·ªõng d·∫´n chi ti·∫øt v·ªÅ c√¥ng c·ª• tinh ch·ªânh hi·ªán ƒë·∫°i. | [Article](https://mlabonne.github.io/blog/posts/A_Beginners_Guide_to_LLM_Finetuning.html) | W.I.P. |
| Tinh ch·ªânh m√¥ h√¨nh Mistral-7b model v·ªõi DPO | TƒÉng c∆∞·ªùng hi·ªáu su·∫•t c·ªßa c√°c m√¥ h√¨nh tinh ch·ªânh ƒë∆∞·ª£c gi√°m s√°t v·ªõi DPO. | [Tweet](https://twitter.com/maximelabonne/status/1729936514107290022) | <a href="https://colab.research.google.com/drive/15iFBr1xWgztXvhrj5I9fBv20c7CFOPBE?usp=sharing"><img src="images/colab.svg" alt="Open In Colab"></a> |

### L∆∞·ª£ng t·ª≠ h√≥a (Quantization)

| Notebook | M√¥ t·∫£ | B√†i vi·∫øt | Notebook |
|---------------------------------------|-------------------------------------------------------------------------|---------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------|
| 1. Gi·ªõi thi·ªáu v·ªÅ L∆∞·ª£ng t·ª≠ h√≥a tr·ªçng s·ªë | T·ªëi ∆∞u h√≥a m√¥ h√¨nh ng√¥n ng·ªØ l·ªõn b·∫±ng c√°ch s·ª≠ d·ª•ng l∆∞·ª£ng t·ª≠ h√≥a 8 bit. | [Article](https://mlabonne.github.io/blog/posts/Introduction_to_Weight_Quantization.html) | <a href="https://colab.research.google.com/drive/1DPr4mUQ92Cc-xf4GgAaB6dFcFnWIvqYi?usp=sharing"><img src="images/colab.svg" alt="Open In Colab"></a> |
| 2. L∆∞·ª£ng t·ª≠ h√≥a LLM 4 bit b·∫±ng GPTQ | L∆∞·ª£ng t·ª≠ h√≥a m√¥ h√¨nh LLM c·ªßa b·∫°n v√† ch·∫°y tr√™n m√°y ng∆∞·ªùi d√πng. | [Article](https://mlabonne.github.io/blog/4bit_quantization/) | <a href="https://colab.research.google.com/drive/1lSvVDaRgqQp_mWK_jC9gydz6_-y6Aq4A?usp=sharing"><img src="images/colab.svg" alt="Open In Colab"></a> |
| 3. L∆∞·ª£ng t·ª≠ m√¥ h√¨nh Llama 2 v·ªõi GGUF v√† llama.cpp | L∆∞·ª£ng t·ª≠ m√¥ h√¨nh Llama 2 v·ªõi llama.cpp v√† t·∫£i GGUF l√™n HF Hub. | [Article](https://mlabonne.github.io/blog/posts/Quantize_Llama_2_models_using_ggml.html) | <a href="https://colab.research.google.com/drive/1pL8k7m04mgE5jo2NrjGi8atB0j_37aDD?usp=sharing"><img src="images/colab.svg" alt="Open In Colab"></a> |
| 4. ExLlamaV2: Th∆∞ vi·ªán nhanh nh·∫•t ƒë·ªÉ ch·∫°y LLM | L∆∞·ª£ng t·ª≠ h√≥a v√† ch·∫°y m√¥ h√¨nh EXL2¬†v√† t·∫£i ch√∫ng l√™n HF Hub. | [Article](https://mlabonne.github.io/blog/posts/ExLlamaV2_The_Fastest_Library_to_Run%C2%A0LLMs.html) | <a href="https://colab.research.google.com/drive/1yrq4XBlxiA0fALtMoT2dwiACVc77PHou?usp=sharing"><img src="images/colab.svg" alt="Open In Colab"></a> |

### Kh√°c

| Notebook | M√¥ t·∫£ | B√†i vi·∫øt | Notebook |
|---------------------------------------|-------------------------------------------------------------------------|---------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------|
| H·ª£p nh·∫•t LLM v·ªõi Mergekit | K·∫øt h·ª£p nhi·ªÅu LLM v√† t·∫°o m√¥ h√¨nh Frankenstein c·ªßa ri√™ng b·∫°n | [Tweet](https://twitter.com/maximelabonne/status/1740732104554807676) | <a href="https://colab.research.google.com/drive/1_JS7JKJAQozD48-LhYdegcuuZ2ddgXfr?usp=sharing"><img src="images/colab.svg" alt="Open In Colab"></a> |
| Chi·∫øn l∆∞·ª£c gi·∫£i m√£ trong c√°c m√¥ h√¨nh ng√¥n ng·ªØ l·ªõn | H∆∞·ªõng d·∫´n t·∫°o vƒÉn b·∫£n t·ª´ t√¨m ki·∫øm ch√πm tia ƒë·∫øn l·∫•y m·∫´u h·∫°t nh√¢n | [Article](https://mlabonne.github.io/blog/posts/2022-06-07-Decoding_strategies.html) | <a href="https://colab.research.google.com/drive/19CJlOS5lI29g-B3dziNn93Enez1yiHk2?usp=sharing"><img src="images/colab.svg" alt="Open In Colab"></a> |
| Tr·ª±c quan h√≥a h√†m m·∫•t m√°t c·ªßa GPT-2 | S∆° ƒë·ªì 3D tr·ª±c quan h√†m m·∫•t m√°t d·ª±a tr√™n s·ª± nhi·ªÖu lo·∫°n tr·ªçng s·ªë. | [Tweet](https://twitter.com/maximelabonne/status/1667618081844219904) | <a href="https://colab.research.google.com/drive/1Fu1jikJzFxnSPzR_V2JJyDVWWJNXssaL?usp=sharing"><img src="images/colab.svg" alt="Open In Colab"></a> |
| C·∫£i thi·ªán ChatGPT b·∫±ng S∆° ƒë·ªì tri th·ª©c | TƒÉng c∆∞·ªùng c√¢u tr·∫£ l·ªùi c·ªßa ChatGPT b·∫±ng bi·ªÉu ƒë·ªì tri th·ª©c. | [Article](https://mlabonne.github.io/blog/posts/Article_Improve_ChatGPT_with_Knowledge_Graphs.html) | <a href="https://colab.research.google.com/drive/1mwhOSw9Y9bgEaIFKT4CLi0n18pXRM4cj?usp=sharing"><img src="images/colab.svg" alt="Open In Colab"></a> |

## üß© C∆° b·∫£n v·ªÅ LLM

![](images/roadmap_fundamentals.png)

### 1. To√°n h·ªçc cho h·ªçc m√°y

Tr∆∞·ªõc khi th√†nh th·∫°o machine learning, ƒëi·ªÅu quan tr·ªçng l√† ph·∫£i hi·ªÉu c√°c kh√°i ni·ªám to√°n h·ªçc c∆° b·∫£n h·ªó tr·ª£ c√°c thu·∫≠t to√°n n√†y.

- **ƒê·∫°i s·ªë tuy·∫øn t√≠nh (Linear Algebra)**: M√¥n n√†y r·∫•t quan tr·ªçng ƒë·ªÉ hi·ªÉu nhi·ªÅu thu·∫≠t to√°n, ƒë·∫∑c bi·ªát l√† nh·ªØng thu·∫≠t to√°n ƒë∆∞·ª£c s·ª≠ d·ª•ng trong h·ªçc s√¢u. C√°c kh√°i ni·ªám ch√≠nh bao g·ªìm vect∆°, ma tr·∫≠n, ƒë·ªãnh th·ª©c, gi√° tr·ªã ri√™ng v√† vect∆° ri√™ng, kh√¥ng gian vect∆° v√† c√°c ph√©p bi·∫øn ƒë·ªïi tuy·∫øn t√≠nh.
- **Gi·∫£i t√≠ch (Calculus)**: Nhi·ªÅu thu·∫≠t to√°n h·ªçc m√°y li√™n quan ƒë·∫øn vi·ªác t·ªëi ∆∞u h√≥a c√°c h√†m li√™n t·ª•c, ƒë√≤i h·ªèi s·ª± hi·ªÉu bi·∫øt v·ªÅ ƒë·∫°o h√†m, t√≠ch ph√¢n, gi·ªõi h·∫°n v√† chu·ªói. Ph√©p t√≠nh ƒëa bi·∫øn v√† kh√°i ni·ªám gradient c≈©ng r·∫•t quan tr·ªçng.
- **X√°c su·∫•t v√† Th·ªëng k√™**: ƒê√¢y l√† nh·ªØng th√¥ng tin quan tr·ªçng ƒë·ªÉ hi·ªÉu c√°ch c√°c m√¥ h√¨nh h·ªçc h·ªèi t·ª´ d·ªØ li·ªáu v√† ƒë∆∞a ra d·ª± ƒëo√°n. C√°c kh√°i ni·ªám ch√≠nh bao g·ªìm l√Ω thuy·∫øt x√°c su·∫•t, bi·∫øn ng·∫´u nhi√™n, ph√¢n b·ªë x√°c su·∫•t, k·ª≥ v·ªçng, ph∆∞∆°ng sai, hi·ªáp ph∆∞∆°ng sai, t∆∞∆°ng quan, ki·ªÉm tra gi·∫£ thuy·∫øt, kho·∫£ng tin c·∫≠y, ∆∞·ªõc t√≠nh kh·∫£ nƒÉng t·ªëi ƒëa v√† suy lu·∫≠n Bayes.

üìö T√†i nguy√™n h·ªçc t·∫≠p:

- [3Blue1Brown - The Essence of Linear Algebra](https://www.youtube.com/watch?v=fNk_zzaMoSs&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab): Chu·ªói video cung c·∫•p tr·ª±c quan h√¨nh h·ªçc cho c√°c kh√°i ni·ªám n√†y.
- [StatQuest with Josh Starmer - Statistics Fundamentals](https://www.youtube.com/watch?v=qBigTkBLU6g&list=PLblh5JKOoLUK0FLuzwntyYI10UQFUhsY9): Cung c·∫•p nh·ªØng gi·∫£i th√≠ch ƒë∆°n gi·∫£n v√† r√µ r√†ng cho nhi·ªÅu kh√°i ni·ªám th·ªëng k√™.
- [Immersive Linear Algebra](https://immersivemath.com/ila/learnmore.html): M·ªôt c√°ch gi·∫£i th√≠ch tr·ª±c quan kh√°c v·ªÅ ƒë·∫°i s·ªë tuy·∫øn t√≠nh.
- [Khan Academy - Linear Algebra](https://www.khanacademy.org/math/linear-algebra): T·ªët cho ng∆∞·ªùi m·ªõi b·∫Øt ƒë·∫ßu v√¨ n√≥ gi·∫£i th√≠ch c√°c kh√°i ni·ªám m·ªôt c√°ch r·∫•t tr·ª±c quan.
- [Khan Academy - Calculus](https://www.khanacademy.org/math/calculus-1): Kh√≥a h·ªçc t∆∞∆°ng t√°c bao g·ªìm t·∫•t c·∫£ nh·ªØng ki·∫øn th·ª©c c∆° b·∫£n v·ªÅ t√≠nh to√°n.
- [Khan Academy - Probability and Statistics](https://www.khanacademy.org/math/statistics-probability): T√†i li·ªáu h·ªçc t·∫≠p d·ªÖ hi·ªÉu. 
---

### 2. Python cho h·ªçc m√°y (Machine Learning)

Python l√† ng√¥n ng·ªØ l·∫≠p tr√¨nh m·∫°nh m·∫Ω v√† linh ho·∫°t, ƒë·∫∑c bi·ªát t·ªët cho machine learning nh·ªù t√≠nh d·ªÖ ƒë·ªçc, t√≠nh nh·∫•t qu√°n v√† h·ªá sinh th√°i m·∫°nh m·∫Ω c·ªßa c√°c th∆∞ vi·ªán khoa h·ªçc d·ªØ li·ªáu.

- **Kh√°i ni·ªám c∆° b·∫£n v·ªÅ Python**: Vi·ªác hi·ªÉu bi·∫øt v·ªÅ c√∫ ph√°p c∆° b·∫£n, ki·ªÉu d·ªØ li·ªáu, x·ª≠ l√Ω l·ªói v√† l·∫≠p tr√¨nh h∆∞·ªõng ƒë·ªëi t∆∞·ª£ng c·ªßa Python l√† r·∫•t quan tr·ªçng.
- **Th∆∞ vi·ªán khoa h·ªçc d·ªØ li·ªáu**: B·∫Øt bu·ªôc ph·∫£i l√†m quen v·ªõi NumPy cho c√°c ph√©p to√°n s·ªë, Pandas ƒë·ªÉ thao t√°c v√† ph√¢n t√≠ch d·ªØ li·ªáu, Matplotlib v√† Seaborn ƒë·ªÉ tr·ª±c quan h√≥a d·ªØ li·ªáu.
- **Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu**: Qu√° tr√¨nh n√†y bao g·ªìm vi·ªác chia t·ª∑ l·ªá v√† chu·∫©n h√≥a thu·ªôc t√≠nh, x·ª≠ l√Ω d·ªØ li·ªáu b·ªã thi·∫øu, ph√°t hi·ªán ngo·∫°i l·ªá, m√£ h√≥a d·ªØ li·ªáu theo ph√¢n lo·∫°i v√† chia d·ªØ li·ªáu th√†nh c√°c t·∫≠p hu·∫•n luy·ªán, x√°c th·ª±c v√† ki·ªÉm tra.
- **Th∆∞ vi·ªán cho h·ªçc m√°y**: Th√†nh th·∫°o Scikit-learn - th∆∞ vi·ªán cung c·∫•p nhi·ªÅu l·ª±a ch·ªçn thu·∫≠t to√°n h·ªçc c√≥ gi√°m s√°t v√† kh√¥ng gi√°m s√°t -l√† r·∫•t quan tr·ªçng. Hi·ªÉu c√°ch tri·ªÉn khai c√°c thu·∫≠t to√°n nh∆∞ h·ªìi quy tuy·∫øn t√≠nh, h·ªìi quy logistic, c√¢y quy·∫øt ƒë·ªãnh, r·ª´ng ng·∫´u nhi√™n, k-l√°ng gi·ªÅng g·∫ßn nh·∫•t (K-NN) v√† ph√¢n c·ª•m K-mean . C√°c k·ªπ thu·∫≠t gi·∫£m k√≠ch th∆∞·ªõc nh∆∞ PCA v√† t-SNE c≈©ng r·∫•t h·ªØu √≠ch ƒë·ªÉ hi·ªÉn th·ªã d·ªØ li·ªáu nhi·ªÅu chi·ªÅu.

üìö T√†i nguy√™n:

- [Real Python](https://realpython.com/): M·ªôt ngu·ªìn t√†i nguy√™n to√†n di·ªán v·ªõi c√°c b√†i vi·∫øt v√† h∆∞·ªõng d·∫´n cho c·∫£ kh√°i ni·ªám Python d√†nh cho ng∆∞·ªùi m·ªõi b·∫Øt ƒë·∫ßu v√† n√¢ng cao.
- [freeCodeCamp - Learn Python](https://www.youtube.com/watch?v=rfscVS0vtbw): Video d√†i cung c·∫•p ph·∫ßn gi·ªõi thi·ªáu ƒë·∫ßy ƒë·ªß v·ªÅ t·∫•t c·∫£ c√°c kh√°i ni·ªám c·ªët l√µi trong Python.
- [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/): Cu·ªën s√°ch k·ªπ thu·∫≠t s·ªë mi·ªÖn ph√≠ l√† ngu·ªìn t√†i nguy√™n tuy·ªát v·ªùi ƒë·ªÉ h·ªçc v·ªÅ panda, NumPy, matplotlib v√† Seaborn.
- [freeCodeCamp - Machine Learning for Everybody](https://youtu.be/i_LwzRVP7bg): Gi·ªõi thi·ªáu th·ª±c t·∫ø v·ªÅ c√°c thu·∫≠t to√°n h·ªçc m√°y kh√°c nhau cho ng∆∞·ªùi m·ªõi b·∫Øt ƒë·∫ßu.
- [Udacity - Intro to Machine Learning](https://www.udacity.com/course/intro-to-machine-learning--ud120): Kh√≥a h·ªçc mi·ªÖn ph√≠ bao g·ªìm PCA v√† m·ªôt s·ªë kh√°i ni·ªám h·ªçc m√°y kh√°c.

---

### 3. M·∫°ng n∆° ron (Neural Networks)

M·∫°ng l∆∞·ªõi th·∫ßn kinh l√† m·ªôt ph·∫ßn c∆° b·∫£n c·ªßa nhi·ªÅu m√¥ h√¨nh h·ªçc m√°y, ƒë·∫∑c bi·ªát l√† trong lƒ©nh v·ª±c h·ªçc s√¢u. ƒê·ªÉ s·ª≠ d·ª•ng ch√∫ng m·ªôt c√°ch hi·ªáu qu·∫£, c·∫ßn ph·∫£i c√≥ s·ª± hi·ªÉu bi·∫øt to√†n di·ªán v·ªÅ thi·∫øt k·∫ø v√† c∆° ch·∫ø c·ªßa ch√∫ng.

- **C∆° b·∫£n**: G·ªìm vi·ªác hi·ªÉu c·∫•u tr√∫c c·ªßa m·∫°ng l∆∞·ªõi th·∫ßn kinh nh∆∞ c√°c l·ªõp, tr·ªçng s·ªë, ƒë·ªô l·ªách, h√†m k√≠ch ho·∫°t (sigmoid, tanh, ReLU, v.v.)
- **Hu·∫•n luy·ªán v√† t·ªëi ∆∞u**: L√†m quen v·ªõi lan truy·ªÅn ng∆∞·ª£c v√† c√°c lo·∫°i h√†m m·∫•t m√°t kh√°c nhau, nh∆∞ L·ªói b√¨nh ph∆∞∆°ng trung b√¨nh (MSE) v√† Entropy ch√©o. Hi·ªÉu c√°c thu·∫≠t to√°n t·ªëi ∆∞u h√≥a kh√°c nhau nh∆∞ Gi·∫£m d·∫ßn ƒë·ªô d·ªëc, Gi·∫£m d·∫ßn ƒë·ªô d·ªëc ng·∫´u nhi√™n, RMSprop v√† Adam.
- **Overfitting**: Hi·ªÉu kh√°i ni·ªám v·ªÅ overfitting (trong ƒë√≥ m·ªôt m√¥ h√¨nh ho·∫°t ƒë·ªông t·ªët tr√™n d·ªØ li·ªáu hu·∫•n luy·ªán nh∆∞ng k√©m tr√™n d·ªØ li·ªáu kh√¥ng nh√¨n th·∫•y) v√† c√°c k·ªπ thu·∫≠t ch√≠nh quy h√≥a kh√°c nhau ƒë·ªÉ ngƒÉn ch·∫∑n overfitting. C√°c k·ªπ thu·∫≠t bao g·ªìm dropout, chu·∫©n h√≥a L1/L2, d·ª´ng s·ªõm v√† tƒÉng c∆∞·ªùng d·ªØ li·ªáu.
- **Tri·ªÉn khai Perceptron ƒëa l·ªõp (MLP)**: X√¢y d·ª±ng MLP, c√≤n ƒë∆∞·ª£c g·ªçi l√† m·∫°ng ƒë∆∞·ª£c k·∫øt n·ªëi ƒë·∫ßy ƒë·ªß, s·ª≠ d·ª•ng PyTorch.

üìö T√†i nguy√™n:

- [3Blue1Brown - But what is a Neural Network?](https://www.youtube.com/watch?v=aircAruvnKk): Video n√†y ƒë∆∞a ra l·ªùi gi·∫£i th√≠ch tr·ª±c quan v·ªÅ m·∫°ng l∆∞·ªõi th·∫ßn kinh v√† ho·∫°t ƒë·ªông b√™n trong c·ªßa ch√∫ng.
- [freeCodeCamp - Deep Learning Crash Course](https://www.youtube.com/watch?v=VyWAvY2CF9c): Video n√†y gi·ªõi thi·ªáu m·ªôt c√°ch hi·ªáu qu·∫£ t·∫•t c·∫£ c√°c kh√°i ni·ªám quan tr·ªçng nh·∫•t trong h·ªçc s√¢u.
- [Fast.ai - Practical Deep Learning](https://course.fast.ai/): Kh√≥a h·ªçc mi·ªÖn ph√≠ ƒë∆∞·ª£c thi·∫øt k·∫ø d√†nh cho nh·ªØng ng∆∞·ªùi c√≥ kinh nghi·ªám vi·∫øt m√£ mu·ªën t√¨m hi·ªÉu v·ªÅ deep learning.
- [Patrick Loeber - PyTorch Tutorials](https://www.youtube.com/playlist?list=PLqnslRFeH2UrcDBWF5mfPGpqQDSta6VK4): lo·∫°t video d√†nh cho ng∆∞·ªùi m·ªõi b·∫Øt ƒë·∫ßu t√¨m hi·ªÉu v·ªÅ PyTorch.

---

### 4. X·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n (NLP)

NLP l√† m·ªôt nh√°nh c·ªßa tr√≠ tu·ªá nh√¢n t·∫°o gi√∫p thu h·∫πp kho·∫£ng c√°ch gi·ªØa ng√¥n ng·ªØ con ng∆∞·ªùi v√† s·ª± hi·ªÉu bi·∫øt c·ªßa m√°y m√≥c. T·ª´ x·ª≠ l√Ω vƒÉn b·∫£n ƒë∆°n gi·∫£n ƒë·∫øn hi·ªÉu c√°c s·∫Øc th√°i ng√¥n ng·ªØ, NLP ƒë√≥ng m·ªôt vai tr√≤ quan tr·ªçng trong nhi·ªÅu ·ª©ng d·ª•ng nh∆∞ d·ªãch thu·∫≠t, ph√¢n t√≠ch t√¨nh c·∫£m, chatbot, v.v.

- **Ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n**: T√¨m hi·ªÉu c√°c b∆∞·ªõc ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n kh√°c nhau nh∆∞ m√£ h√≥a (chia vƒÉn b·∫£n th√†nh c√°c t·ª´ ho·∫∑c c√¢u), r√∫t g·ªçn t·ª´ g·ªëc (r√∫t g·ªçn c√°c t·ª´ v·ªÅ d·∫°ng g·ªëc), t·ª´ v·ª±ng h√≥a (t∆∞∆°ng t·ª± nh∆∞ t√°ch g·ªëc nh∆∞ng c√≥ t√≠nh ƒë·∫øn ng·ªØ c·∫£nh), lo·∫°i b·ªè t·ª´, v.v. .
- **K·ªπ thu·∫≠t tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng**: L√†m quen v·ªõi c√°c k·ªπ thu·∫≠t chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu vƒÉn b·∫£n sang ƒë·ªãnh d·∫°ng m√† thu·∫≠t to√°n m√°y h·ªçc c√≥ th·ªÉ hi·ªÉu ƒë∆∞·ª£c. C√°c ph∆∞∆°ng ph√°p ch√≠nh bao g·ªìm T√∫i t·ª´ (BoW), T·∫ßn s·ªë t√†i li·ªáu ngh·ªãch ƒë·∫£o t·∫ßn s·ªë thu·∫≠t ng·ªØ (TF-IDF) v√† n-gram.
- **Nh√∫ng t·ª´**: Nh√∫ng t·ª´ l√† m·ªôt ki·ªÉu tr√¨nh b√†y t·ª´ cho ph√©p c√°c t·ª´ c√≥ nghƒ©a t∆∞∆°ng t·ª± c√≥ c√°ch tr√¨nh b√†y t∆∞∆°ng t·ª±. C√°c ph∆∞∆°ng th·ª©c ch√≠nh bao g·ªìm Word2Vec, GloVe v√† FastText.
- **M·∫°ng th·∫ßn kinh h·ªìi quy (RNN)**: Hi·ªÉu ho·∫°t ƒë·ªông c·ªßa RNN, m·ªôt lo·∫°i m·∫°ng th·∫ßn kinh ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ ho·∫°t ƒë·ªông v·ªõi d·ªØ li·ªáu chu·ªói. Kh√°m ph√° LSTM v√† GRU, hai bi·∫øn th·ªÉ RNN c√≥ kh·∫£ nƒÉng h·ªçc c√°c ph·∫ßn ph·ª• thu·ªôc l√¢u d√†i.
  
üìö T√†i nguy√™n:

- [RealPython - NLP with spaCy in Python](https://realpython.com/natural-language-processing-spacy-python/): H∆∞·ªõng d·∫´n ƒë·∫ßy ƒë·ªß v·ªÅ th∆∞ vi·ªán spaCy cho c√°c t√°c v·ª• NLP trong Python.
- [Kaggle - NLP Guide](https://www.kaggle.com/learn-guide/natural-language-processing): M·ªôt notebooks v√† t√†i nguy√™n ƒë·ªÉ gi·∫£i th√≠ch th·ª±c t·∫ø v·ªÅ NLP trong Python.
- [Jay Alammar - The Illustration Word2Vec](https://jalammar.github.io/illustrated-word2vec/): T√†i li·ªáu tham kh·∫£o t·ªët ƒë·ªÉ hi·ªÉu ki·∫øn tr√∫c n·ªïi ti·∫øng Word2Vec .
- [Jake Tae - PyTorch RNN from Scratch](https://jaketae.github.io/study/pytorch-rnn/): Tri·ªÉn khai th·ª±c t·∫ø v√† ƒë∆°n gi·∫£n c√°c m√¥ h√¨nh RNN, LSTM v√† GRU trong PyTorch.
- [colah's blog - Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/): B√†i vi·∫øt mang t√≠nh l√Ω thuy·∫øt nhi·ªÅu h∆°n v·ªÅ m·∫°ng LSTM.

## üßë‚Äçüî¨ **Nh√† nghi√™n c·ª©u LLM**

![](images/roadmap_scientist.png)

### 1. Ki·∫øn tr√∫c c·ªßa LLM

While an in-depth knowledge about the Transformer architecture is not required, it is important to have a good understanding of its inputs (tokens) and outputs (logits). The vanilla attention mechanism is another crucial component to master, as improved versions of it are introduced later on.

* **High-level view**: Revisit the encoder-decoder Transformer architecture, and more specifically the decoder-only GPT architecture, which is used in every modern LLM.
* **Tokenization**: Understand how to convert raw text data into a format that the model can understand, which involves splitting the text into tokens (usually words or subwords).
* **Attention mechanisms**: Grasp the theory behind attention mechanisms, including self-attention and scaled dot-product attention, which allows the model to focus on different parts of the input when producing an output.
* **Text generation**: Learn about the different ways the model can generate output sequences. Common strategies include greedy decoding, beam search, top-k sampling, and nucleus sampling.

üìö **References**:
- [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/) by Jay Alammar: A visual and intuitive explanation of the Transformer model.
- [The Illustrated GPT-2](https://jalammar.github.io/illustrated-gpt2/) by Jay Alammar: Even more important than the previous article, it is focused on the GPT architecture, which is very similar to Llama's.
* [nanoGPT](https://www.youtube.com/watch?v=kCc8FmEb1nY) by Andrej Karpathy: A 2h-long YouTube video to reimplement GPT from scratch (for programmers).
* [Attention? Attention!](https://lilianweng.github.io/posts/2018-06-24-attention/) by Lilian Weng: Introduce the need for attention in a more formal way.
* [Decoding Strategies in LLMs](https://mlabonne.github.io/blog/posts/2023-06-07-Decoding_strategies.html): Provide code and a visual introduction to the different decoding strategies to generate text.

---
### 2. Building an instruction dataset

While it's easy to find raw data from Wikipedia and other websites, it's difficult to collect pairs of instructions and answers in the wild. Like in traditional machine learning, the quality of the dataset will directly influence the quality of the model, which is why it might be the most important component in the fine-tuning process.

* **[Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html)-like dataset**: Generate synthetic data from scratch with the OpenAI API (GPT). You can specify seeds and system prompts to create a diverse dataset.
* **Advanced techniques**: Learn how to improve existing datasets with [Evol-Instruct](https://arxiv.org/abs/2304.12244), how to generate high-quality synthetic data like in the [Orca](https://arxiv.org/abs/2306.02707) and [phi-1](https://arxiv.org/abs/2306.11644) papers.
* **Filtering data**: Traditional techniques involving regex, removing near-duplicates, focusing on answers with a high number of tokens, etc.
* **Prompt templates**: There's no true standard way of formatting instructions and answers, which is why it's important to know about the different chat templates, such as [ChatML](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/chatgpt?tabs=python&pivots=programming-language-chat-ml), [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html), etc.

üìö **References**:
* [Preparing a Dataset for Instruction tuning](https://wandb.ai/capecape/alpaca_ft/reports/How-to-Fine-Tune-an-LLM-Part-1-Preparing-a-Dataset-for-Instruction-Tuning--Vmlldzo1NTcxNzE2) by Thomas Capelle: Exploration of the Alpaca and Alpaca-GPT4 datasets and how to format them.
* [Generating a Clinical Instruction Dataset](https://medium.com/mlearning-ai/generating-a-clinical-instruction-dataset-in-portuguese-with-langchain-and-gpt-4-6ee9abfa41ae) by Solano Todeschini: Tutorial on how to create a synthetic instruction dataset using GPT-4. 
* [GPT 3.5 for news classification](https://medium.com/@kshitiz.sahay26/how-i-created-an-instruction-dataset-using-gpt-3-5-to-fine-tune-llama-2-for-news-classification-ed02fe41c81f) by Kshitiz Sahay: Use GPT 3.5 to create an instruction dataset to fine-tune Llama 2 for news classification.
* [Dataset creation for fine-tuning LLM](https://colab.research.google.com/drive/1GH8PW9-zAe4cXEZyOIE-T9uHXblIldAg?usp=sharing): Notebook that contains a few techniques to filter a dataset and upload the result.
* [Chat Template](https://huggingface.co/blog/chat-templates) by Matthew Carrigan: Hugging Face's page about prompt templates

---
### 3. Pre-training models

Pre-training is a very long and costly process, which is why this is not the focus of this course. It's good to have some level of understanding of what happens during pre-training, but hands-on experience is not required.

* **Data pipeline**: Pre-training requires huge datasets (e.g., [Llama 2](https://arxiv.org/abs/2307.09288) was trained on 2 trillion tokens) that need to be filtered, tokenized, and collated with a pre-defined vocabulary.
* **Causal language modeling**: Learn the difference between causal and masked language modeling, as well as the loss function used in this case. For efficient pre-training, learn more about [Megatron-LM](https://github.com/NVIDIA/Megatron-LM).
* **Scaling laws**: The [scaling laws](https://arxiv.org/pdf/2001.08361.pdf) describe the expected model performance based on the model size, dataset size, and the amount of compute used for training.
* **High-Performance Computing**: Out of scope here, but more knowledge about HPC is fundamental if you're planning to create your own LLM from scratch (hardware, distributed workload, etc.).

üìö **References**:
* [LLMDataHub](https://github.com/Zjh-819/LLMDataHub) by Junhao Zhao: Curated list of datasets for pre-training, fine-tuning, and RLHF.
* [Training a causal language model from scratch](https://huggingface.co/learn/nlp-course/chapter7/6?fw=pt) by Hugging Face: Pre-train a GPT-2 model from scratch using the transformers library.
* [Megatron-LM](https://github.com/NVIDIA/Megatron-LM): State-of-the-art library to efficiently pre-train models.
* [TinyLlama](https://github.com/jzhang38/TinyLlama) by Zhang et al.: Check this project to get a good understanding of how a Llama model is trained from scratch.
* [Causal language modeling](https://huggingface.co/docs/transformers/tasks/language_modeling) by Hugging Face: Explain the difference between causal and masked language modeling and how to quickly fine-tune a DistilGPT-2 model.
* [Chinchilla's wild implications](https://www.lesswrong.com/posts/6Fpvch8RR29qLEWNH/chinchilla-s-wild-implications) by nostalgebraist: Discuss the scaling laws and explain what they mean to LLMs in general.
* [BLOOM](https://bigscience.notion.site/BLOOM-BigScience-176B-Model-ad073ca07cdf479398d5f95d88e218c4) by BigScience: Notion pages that describes how the BLOOM model was built, with a lot of useful information about the engineering part and the problems that were encountered.
* [OPT-175 Logbook](https://github.com/facebookresearch/metaseq/blob/main/projects/OPT/chronicles/OPT175B_Logbook.pdf) by Meta: Research logs showing what went wrong and what went right. Useful if you're planning to pre-train a very large language model (in this case, 175B parameters).

---
### 4. Supervised Fine-Tuning

Pre-trained models are only trained on a next-token prediction task, which is why they're not helpful assistants. SFT allows you to tweak them into responding to instructions. Moreover, it allows you to fine-tune your model on any data (private, not seen by GPT-4, etc.) and use it without having to pay for an API like OpenAI's.

* **Full fine-tuning**: Full fine-tuning refers to training all the parameters in the model. It is not an efficient technique, but it produces slightly better results.
* [**LoRA**](https://arxiv.org/abs/2106.09685): A parameter-efficient technique (PEFT) based on low-rank adapters. Instead of training all the parameters, we only train these adapters.
* [**QLoRA**](https://arxiv.org/abs/2305.14314): Another PEFT based on LoRA, which also quantizes the weights of the model in 4 bits and introduce paged optimizers to manage memory spikes.
* **[Axolotl](https://github.com/OpenAccess-AI-Collective/axolotl)**: A user-friendly and powerful fine-tuning tool that is used in a lot of state-of-the-art open-source models.
* [**DeepSpeed**](https://www.deepspeed.ai/): Efficient pre-training and fine-tuning of LLMs for multi-GPU and multi-node settings (implemented in Axolotl).

üìö **References**:
* [The Novice's LLM Training Guide](https://rentry.org/llm-training) by Alpin: Overview of the main concepts and parameters to consider when fine-tuning LLMs.
* [LoRA insights](https://lightning.ai/pages/community/lora-insights/) by Sebastian Raschka: Practical insights about LoRA and how to select the best parameters.
* [Fine-Tune Your Own Llama 2 Model](https://mlabonne.github.io/blog/posts/Fine_Tune_Your_Own_Llama_2_Model_in_a_Colab_Notebook.html): Hands-on tutorial on how to fine-tune a Llama 2 model using Hugging Face libraries.
* [Padding Large Language Models](https://towardsdatascience.com/padding-large-language-models-examples-with-llama-2-199fb10df8ff) by Benjamin Marie: Best practices to pad training examples for causal LLMs
* [A Beginner's Guide to LLM Fine-Tuning](https://mlabonne.github.io/blog/posts/A_Beginners_Guide_to_LLM_Finetuning.html): Tutorial on how to fine-tune a CodeLlama model using Axolotl.

---
### 5. Reinforcement Learning from Human Feedback

After supervised fine-tuning, RLHF is a step used to align the LLM's answers with human expectations. The idea is to learn preferences from human (or artificial) feedback, which can be used to reduce biases, censor models, or make them act in a more useful way. It is more complex than SFT and often seen as optional.

* **Preference datasets**: These datasets typically contain several answers with some kind of ranking, which makes them more difficult to produce than instruction datasets.
* [**Proximal Policy Optimization**](https://arxiv.org/abs/1707.06347): This algorithm leverages a reward model that predicts whether a given text is highly ranked by humans. This prediction is then used to optimize the SFT model with a penalty based on KL divergence.
* **[Direct Preference Optimization](https://arxiv.org/abs/2305.18290)**: DPO simplifies the process by reframing it as a classification problem. It uses a reference model instead of a reward model (no training needed) and only requires one hyperparameter, making it more stable and efficient.

üìö **References**:
* [An Introduction to Training LLMs using RLHF](https://wandb.ai/ayush-thakur/Intro-RLAIF/reports/An-Introduction-to-Training-LLMs-Using-Reinforcement-Learning-From-Human-Feedback-RLHF---VmlldzozMzYyNjcy) by Ayush Thakur: Explain why RLHF is desirable to reduce bias and increase performance in LLMs.
* [Illustration RLHF](https://huggingface.co/blog/rlhf) by Hugging Face: Introduction to RLHF with reward model training and fine-tuning with reinforcement learning.
* [StackLLaMA](https://huggingface.co/blog/stackllama) by Hugging Face: Tutorial to efficiently align a LLaMA model with RLHF using the transformers library.
* [Fine-tune Llama 2 with DPO](https://huggingface.co/blog/dpo-trl) by Hugging Face: Tutorial to fine-tune a Llama 2 model with DPO.
* [LLM Training: RLHF and Its Alternatives](https://substack.com/profile/27393275-sebastian-raschka-phd) by Sebastian Rashcka: Overview of the RLHF process and alternatives like RLAIF.

---
### 6. Evaluation

Evaluating LLMs is an undervalued part of the pipeline, which is time-consuming and moderately reliable. Your downstream task should dictate what you want to evaluate, but always remember the Goodhart's law: "when a measure becomes a target, it ceases to be a good measure."

* **Traditional metrics**: Metrics like perplexity and BLEU score are not popular as they were because they're flawed in most contexts. It is still important to understand them and when they can be applied.
* **General benchmarks**: Based on the [Language Model Evaluation Harness](https://github.com/EleutherAI/lm-evaluation-harness), the [Open LLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard) is the main benchmark for general-purpose LLMs (like ChatGPT). There are other popular benchmarks like [BigBench](https://github.com/google/BIG-bench), [MT-Bench](https://arxiv.org/abs/2306.05685), etc.
* **Task-specific benchmarks**: Tasks like summarization, translation, question answering have dedicated benchmarks, metrics, and even subdomains (medical, financial, etc.), such as [PubMedQA](https://pubmedqa.github.io/) for biomedical question answering.
* **Human evaluation**: The most reliable evaluation is the acceptance rate by users or comparisons made by humans. If you want to know if a model performs well, the simplest but surest way is to use it yourself.

üìö **References**:
* [Perplexity of fixed-length models](https://huggingface.co/docs/transformers/perplexity) by Hugging Face: Overview of perplexity with code to implement it with the transformers library.
* [BLEU at your own risk](https://towardsdatascience.com/evaluating-text-output-in-nlp-bleu-at-your-own-risk-e8609665a213) by Rachael Tatman: Overview of the BLEU score and its many issues with examples.
* [A Survey on Evaluation of LLMs](https://arxiv.org/abs/2307.03109) by Chang et al.: Comprehensive paper about what to evaluate, where to evaluate, and how to evaluate.
* [Chatbot Arena Leaderboard](https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard) by lmsys: Elo rating of general-purpose LLMs, based on comparisons made by humans.

---
### 7. Quantization

Quantization is the process of converting the weights (and activations) of a model using a lower precision. For example, weights stored using 16 bits can be converted into a 4-bit representation. This technique has become increasingly important to reduce the computational and memory costs associated to LLMs.

* **Base techniques**: Learn the different levels of precision (FP32, FP16, INT8, etc.) and how to perform na√Øve quantization with absmax and zero-point techniques.
* **GGUF and llama.cpp**: Originally designed to run on CPUs, [llama.cpp](https://github.com/ggerganov/llama.cpp) and the GGUF format have become the most popular tools to run LLMs on consumer-grade hardware.
* **GPTQ and EXL2**: [GPTQ](https://arxiv.org/abs/2210.17323) and, more specifically, the [EXL2](https://github.com/turboderp/exllamav2) format offer an incredible speed but can only run on GPUs. Models also take a long time to be quantized.
* **AWQ**: This new format is more accurate than GPTQ (lower perplexity) but uses a lot more VRAM and is not necessarily faster.

üìö **References**:
* [Introduction to quantization](https://mlabonne.github.io/blog/posts/Introduction_to_Weight_Quantization.html): Overview of quantization, absmax and zero-point quantization, and LLM.int8() with code.
* [Quantize Llama models with llama.cpp](https://mlabonne.github.io/blog/posts/Quantize_Llama_2_models_using_ggml.html): Tutorial on how to quantize a Llama 2 model using llama.cpp and the GGUF format.
* [4-bit LLM Quantization with GPTQ](https://mlabonne.github.io/blog/posts/Introduction_to_Weight_Quantization.html): Tutorial on how to quantize an LLM using the GPTQ algorithm with AutoGPTQ.
* [ExLlamaV2: The Fastest Library to Run LLMs](https://mlabonne.github.io/blog/posts/ExLlamaV2_The_Fastest_Library_to_Run%C2%A0LLMs.html): Guide on how to quantize a Mistral model using the EXL2 format and run it with the ExLlamaV2 library.
* [Understanding Activation-Aware Weight Quantization](https://medium.com/friendliai/understanding-activation-aware-weight-quantization-awq-boosting-inference-serving-efficiency-in-10bb0faf63a8) by FriendliAI: Overview of the AWQ technique and its benefits.

---
### 8. Inference optimization

* **Flash Attention**: Optimization of the attention mechanism to transform its complexity from quadratic to linear, speeding up both training and inference.
* **Key-value cache**: Understand the key-value cache and the improvements introduced in [Multi-Query Attention](https://arxiv.org/abs/1911.02150) (MQA) and [Grouped-Query Attention](https://arxiv.org/abs/2305.13245) (GQA).
* **Speculative decoding**: Use a small model to produce drafts that are then reviewed by a larger model to speed up text generation.
* **Positional encoding**: Understand positional encodings in transformers, particularly relative schemes like [RoPE](https://arxiv.org/abs/2104.09864), [ALiBi](https://arxiv.org/abs/2108.12409), and [YaRN](https://arxiv.org/abs/2309.00071). (Not directly connected to inference optimization but to longer context windows.)

üìö **References**:
* [GPU Inference](https://huggingface.co/docs/transformers/main/en/perf_infer_gpu_one) by Hugging Face: Explain how to optimize inference on GPUs.
* [Optimizing LLMs for Speed and Memory](https://huggingface.co/docs/transformers/main/en/llm_tutorial_optimization) by Hugging Face: Explain three main techniques to optimize speed and memory, namely quantization, Flash Attention, and architectural innovations.
* [Assisted Generation](https://huggingface.co/blog/assisted-generation) by Hugging Face: HF's version of speculative decoding, it's an interesting blog post about how it works with code to implement it.
* [Extending the RoPE](https://blog.eleuther.ai/yarn/) by EleutherAI: Article that summarizes the different position-encoding techniques.
* [Extending Context is Hard... but not Impossible](https://kaiokendev.github.io/context) by kaiokendev: This blog post introduces the SuperHOT technique and provides an excellent survey of related work.

## üë∑ The LLM Engineer

W.I.P.

---
### Contributions

Feel free to contact me if you think other topics should be mentioned or if the current architecture can be improved.

### Acknowledgements

This roadmap was inspired by the excellent [DevOps Roadmap](https://github.com/milanm/DevOps-Roadmap) from Milan Milanoviƒá and Romano Roth.

Special thanks to Thomas Thelen for motivating me to create a roadmap, and Andr√© Frade for his input and review of the first draft.

*Disclaimer: I am not affiliated with any sources listed here.*

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=mlabonne/llm-course&type=Date)](https://star-history.com/#mlabonne/llm-course&Date)
